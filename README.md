# Web-microblog-App-with-Face-Recogntion-Authentification


Developping a Moicroblog Blog Web App where all principals admin and user rights and access are managed by a real time face recognition authentification system 

Nous concevons, d√©veloppons et impl√©mentons dans le cadre de ce projet un syst√®me de vision par ordinateur, orient√© reconnaissance faciale, int√©gr√© subtilement au contr√¥le des acc√®s et √† la gestion des droits des utilisateurs d‚Äôun prototype d‚Äôapplication de microblogage (Partage d‚Äôinformations entre salari√©s d‚Äôune entreprise) en mode ferm√©.

## Phase conception

### D√©tection de visage


Pour la phase de d√©tection, le mod√®le utilis√© est le HOG (Histogramme histogramme de gradient orient√©), en anglais, histogram of oriented gradients) de Dlib que nous verrons dans les lignes suivantes.
Outil consid√©rablement utilis√© dans notre projet, Dlib est une biblioth√®que logicielle multiplateforme √† usage g√©n√©ral √©crite dans le langage de programmation C++. Il s'agit d'un logiciel open source publi√© sous une licence logicielle Boost.

Il contient des composants logiciels pour g√©rer la mise en r√©seau, les threads, les interfaces graphiques utilisateur, les structures de donn√©es, l'alg√®bre lin√©aire, l'apprentissage automatique (machine learning), le traitement d'images, l'exploration de donn√©es, l'analyse XML et de texte, l'optimisation num√©rique, les r√©seaux bay√©siens et diverses autres t√¢ches.

Comme cit√© plus haut, l‚Äôalgorithme HOG de Dlib est l‚Äôoutil utilis√© pour notre phase de localisation de visage. Apr√®s l‚Äôavoir d√©fini, nous pr√©senterons le processus derri√®re cet algorithme et son impl√©mentation.

<img width="720" alt="Capture d‚ÄôeÃÅcran 2022-10-22 aÃÄ 07 44 57" src="https://user-images.githubusercontent.com/113049750/197323373-80747568-125e-4c2a-823b-3621ee956682.png">

Selon Wikip√©dia, un histogramme de gradient orient√© (en anglais, histogram of oriented gradients ou HOG) est une caract√©ristique utilis√©e en vision par ordinateur pour la d√©tection d'objet. Il est bas√© sur le calcul d‚Äôhistogrammes locaux de l'orientation du gradient sur une grille dense (zones r√©guli√®rement r√©parties sur l'image) et est particuli√®rement efficace pour la d√©tection de personnes.



Navneet Dalal et Bill Triggs, chercheurs √† l'INRIA de Grenoble, sont les auteurs de ce proc√©d√©.

Les 5 √©tapes du descripteur de fonctionnalit√© HOG :
Le pr√©traitement (normalisation gamma/couleur et redimensionnement).
Le calcul des gradients de l‚Äôorientation de l‚Äôimage.
Division de l'image en cellules et construction des histogrammes de l‚Äôorientation des gradients.
Normalisation des blocs.
Obtention du vecteur de caract√©ristiques HOG.

##### √âtape 1 : Le pr√©traitement
Le pr√©traitement des images (normalisation des couleurs, redimensionnement) sont typiques de toutes les t√¢ches de vision par ordinateur. Le redimensionnement de l'image et la normalisation des valeurs de pixels constituent des √©tapes tr√®s importantes aussi bien dans l‚Äôapplication de m√©thodes traditionnelles que d‚Äôapprentissage en profondeur (deep learning).
 
Dans l‚Äôapplication du descripteur de caract√©ristiques HOG, la taille d'image la plus courante est de 64 √ó 128 (largeur x hauteur) pixels. Les travaux de Dalal et Triggs portaient principalement sur la reconnaissance et la d√©tection humaines et r√©v√®lent que 64√ó128 est la taille d'image id√©ale, bien qu‚Äôil soit tout √† fait possible d‚Äôutiliser n'importe quelles autres dimensions d'image tant que le ratio largeur /hauteur est 1 : 2 (128√ó256 ou 256√ó512).
 
On proc√®de ensuite √† l‚Äôapplication d‚Äô√©chelles de couleurs ou de normalisation des couleurs. Selon les auteurs les deux espaces colorim√©triques RVB et LAB fonctionnent de mani√®re identique. L‚Äôutilisation d'images en niveaux de gris, cependant r√©duit les performances (le descripteur de fonction HOG donne de meilleurs r√©sultats sur les images color√©es).

##### √âtape 2 : Calcul des gradients de l‚Äôorientation de l‚Äôimage

Lors de l‚Äô√©tape du calcul du gradient, on recourt couramment √† l‚Äôapplication d‚Äôun filtre d√©rivatif 1-D centr√©, dans les directions horizontales et verticales. Les masques utilis√©s sont les suivants : 
Gradient vertical :   [‚àí1,0,1]
Gradient horizontal : [‚àí1,0,1] T
En r√®gle g√©n√©rale, le calcul des gradients de l‚Äôorientation d'une image en vision par ordinateur, r√©v√®le les emplacements o√π les intensit√©s des gradients de pixels changent. Cela conduit √† l‚Äôextraction des informations utiles. Les images suivantes repr√©sentent dans l‚Äôordre l‚Äôimage de d√©part, celle apr√®s l‚Äôapplication des masques horizontal et celle apr√®s l‚Äôapplication du masque vertical.

##### √âtape 3 : Division de l'image en cellules et construction des histogrammes de l‚Äôorientation des gradients
L‚Äôobjectif √† ce niveau est la cr√©ation des histogrammes de l'orientation des gradients. Ceci est fait dans des cellules carr√©es de petite taille (de 4x4 √† 12x12 pixels). On divise ici l'image en cellules de 8 √ó 8. On calcule par la suite, les gradients pour toutes les cellules. 
Chaque pixel de la cellule vote alors pour une classe de l'histogramme, en fonction de l'orientation du gradient √† ce point. Le vote du pixel est pond√©r√© par l'intensit√© du gradient en ce point.  


Dans la mesure o√π l‚Äôimage est de dimension 64 √ó 128, on obtient 8 cellules dans le sens horizontal pour chaque ligne et 16 cellules dans le sens vertical pour chaque colonne. 
Chaque cellule a 8x8x3 = 192 pixels. Et le gradient de chaque cellule poss√®de une magnitude et une direction (2 valeurs). Chaque cellule poss√®de alors 8x8x2 = 128 valeurs comme informations de gradient. 
Les magnitudes des gradients et les directions sont chacun des blocs 8 √ó 8 contenants des nombres. Ils sont repr√©sent√©s √† l'aide de 9 bacs d'orientation (9 valeurs pour une cellule).

On obtient donc 128 histogrammes de ces 9 valeurs correspondant aux 128 cellules dans l'image. La plupart des bacs sont vides sur l‚Äôimage pour la simple et bonne raison qu‚Äôils repr√©sentent la premi√®re cellule de la grille, o√π l'image ne contient pas beaucoup d'informations sur le gradient.


##### √âtape 4 : Normalisation des blocs

Nous avons vu, lors de l‚Äô√©tape pr√©c√©dente, que nous divisons l'image en grilles de cellules de 8*8 pixels et nous calculons ensuite les gradients pour chaque cellule. 
Selon les travaux des auteurs, les valeurs de gradient peuvent varier en fonction de l'√©clairage et du contraste du premier plan et de l'arri√®re-plan.
 	Pour pallier √† ce probl√®me, on proc√®de √† la normalisation de blocs de cellules. Dans de tels cas, la normalisation par bloc tend √† √™tre plus performante que celle par cellule unique. On regroupe donc quelques cellules en un bloc et on normalise les valeurs de gradient de chaque bloc de cellules group√©es.



Nous avons regroup√© 4 cellules pour former un bloc. On parle de normalisation de bloc 2 √ó 2. Il est √©galement possible d‚Äôutiliser une normalisation de bloc 3 √ó 3 (regrouper 9 cellules ensemble). Selon les auteurs, les normalisations de bloc 2 √ó 2 et la normalisation de bloc 3 √ó 3 sont toutes les deux performantes.


##### √âtape 5 : Obtention du vecteur de caract√©ristiques HOG

Lors de la derni√®re √©tape, on proc√®de √† l‚Äô√©tablissement du vecteur de caract√©ristiques HOG.
Apr√®s tous les calculs de normalisations de bloc, ils sont concat√©n√©s en un seul vecteur pour former le vecteur de caract√©ristiques final. A ce niveau, il existe 7 vecteurs horizontaux et 15 vecteurs verticaux. 105 vecteurs au total qui sont concat√©n√©s pour obtenir le vecteur de caract√©ristiques final.
Nous pouvons par la suite utiliser un algorithme d'apprentissage automatique (classificateur supervis√©) tel que Linear SVM pour poursuivre la reconnaissance d‚Äôimage (classification). Cette √©tape ne fait pas partie de la d√©finition du descripteur HOG √† proprement parler et diff√©rents types de classifieurs peuvent √™tre utilis√©s. Dalal et Triggs, choisissent volontairement un classificateur simple, un SVM √† noyau lin√©aire, afin de mesurer essentiellement l'apport des HOG.

Une fois que nous avons correctement organis√© nos donn√©es et nos √©tiquettes, nous devons initialiser un objet Linear SVM et appeler la m√©thode fit () avec les images et les √©tiquettes en tant qu'arguments pour entrainer le SVM lin√©aire sur les caract√©ristiques HOG que nous avons obtenues plus haut.


Ces deux outils (Dlib's HOG + Linear SVM face detector) sont combin√©s √† l‚Äôint√©rieur de la m√©thode get_frontal_face_detector() de Dlib. C‚Äôest le d√©tecteur de visage qu‚Äôil nous faut charger au pr√©alable pour effectuer la phase de d√©tection.


### Extraction des caract√©ristiques

Au cours de cette phase, le syst√®me extrait de l‚Äôimage du visage d√©tect√©, les caract√©ristiques (informations utiles), et les repr√©sente sous la forme d‚Äôun vecteur de 128 dimensions qui est stock√© dans la base de donn√©es pour √™tre utilis√© plus tard lors de la phase de d√©cision (ici, v√©rification).

<img width="360" alt="extrac carac" src="https://user-images.githubusercontent.com/113049750/197323399-7bfb01b9-994b-411c-8ae9-9b78e543adb3.png">

Nous avons besoin, √† ce niveau de charger au pr√©alable tous les mod√®les dont nous avons besoin : 
Un pr√©dicteur de forme pour trouver des rep√®res de visage afin de pouvoir localiser pr√©cis√©ment le visage, et enfin 
Le mod√®le de reconnaissance faciale.

### Le pr√©dicteur de forme

Il permet d‚Äôeffectuer l‚Äôalignement du visage qui est une √©tape cruciale dans la plupart des syst√®mes d‚Äôanalyse de visages car il facilite la d√©tection des caract√©ristiques, donc la reconnaissance du visage. 
Il est n√©cessaire pour cela de d‚Äôabord d√©terminer les points cl√©s appel√©s points de rep√®re au nombre de 68 avec le pr√©dicteur de forme de visage.
Nous utilisons dans ce projet le ‚Äòshape_predictor_68_face_landmarks.dat‚Äô qui permet de pr√©dire la forme ou bien la pose de visage.

<img width="363" alt="face3" src="https://user-images.githubusercontent.com/113049750/197323400-61fdfb14-fcb9-49bb-8611-8358ce6d0de3.png">

Il a √©t√© entrain√© sur le jeu de donn√©es ibug 300-W (300 faces In-the-wild challenge : Database and results) de C. Sagonas, E. Antonakos, G, Tzimiropoulos, S. Zafeiriou, M. Pantic.


Ce pr√©dicteur de forme retourne au mod√®le de reconnaissance un dictionnaire de liste contenant les coordonn√©es des parties caract√©ristiques du visage √† savoir le menton, les deux sourcils, yeux, l√®vres, l‚Äôar√™te et le bout du nez.


<img width="770" alt="face4" src="https://user-images.githubusercontent.com/113049750/197323401-309e4616-cee0-4143-91a3-7f7b0f08354d.png">

Ces coordonn√©es d‚Äôalignement du visage seront sous la forme de (150, 150, 3) et sont plac√©es en entr√©e du mod√®le de reconnaissance pour le reste de la reconnaissance.

### Le mod√®le de reconnaissance

Ce mod√®le est un r√©seau ResNet avec 29 couches de conversion. Il s'agit essentiellement d'une version du r√©seau ResNet-34 de l'article Deep Residual Learning for Image Recognition de He, Zhang, Ren et Sun avec quelques couches supprim√©es et le nombre de filtres par couche r√©duit de moiti√© par l‚Äôauteur Davis King.

 <img width="794" alt="face5" src="https://user-images.githubusercontent.com/113049750/197323402-06755576-a30f-4c82-b483-20fe8bb4fafe.png">


Le r√©seau a √©t√© entrain√© de z√©ro sur un ensemble de donn√©es d'environ 3 millions de visages. Cet ensemble de donn√©es est d√©riv√© d'un certain nombre d'ensembles de donn√©es : l'ensemble de donn√©es Face Scrub, l‚Äôensemble de donn√©es VGG Dataset et un large ensemble un grand nombre d'images r√©cup√©r√©es sur Internet. 
L'ensemble de donn√©es a √©t√© nettoy√© au mieux, en supprimant les erreurs d'√©tiquetage, gr√¢ce √† l'entrainement r√©p√©titif d‚Äôun CNN (r√©seau de neurone convolutif) de reconnaissance faciale, puis des m√©thodes de classification par Graph Clustering et de nombreuses r√©visions manuelles . Environ la moiti√© des images proviennent de VGG et de Scrub Face. Le nombre total d'identit√©s individuelles dans l'ensemble de donn√©es est de 7485.
L‚Äôentrainement du mod√®le a commenc√© avec des poids initialis√©s de mani√®re al√©atoire et un seuil (threshold) de 0,6. Le mod√®le r√©sultant obtient une erreur moyenne de 0,993833 avec un √©cart type de 0,00272732 sur le benchmark LFW.
Il prend en entr√©es 150x150x3 (les donn√©es issues de la phase pr√©c√©dente) et repr√©sente les images de visage sous forme de vecteurs 128 dimensions. Il a obtenu une pr√©cision de 99,38% tandis que les √™tres humains ont √† peine un score de 97,53 % sur le m√™me ensemble de donn√©es. 
Cela signifie que le mod√®le de reconnaissance faciale dlib peut rivaliser avec les autres mod√®les de reconnaissance faciale √† la pointe de la technologie et avec les √™tres humains.

Ce vecteur de 128 dimensions est donc stock√© dans la base de donn√©es pour √™tre utilis√© lors de la phase de v√©rification.

### V√©rification d‚Äôidentit√© 

La derni√®re √©tape de v√©rification de notre syst√®me est celle o√π le syst√®me compare le vecteur obtenu √† partir de l‚Äôimage de l‚Äôutilisateur, gr√¢ce aux √©tapes pr√©c√©dentes, avec celui stock√© au pr√©alable dans la base de donn√©es pour l‚Äôindividu pr√©tendu. Elle se base sur l‚Äôapplication du calcul de la Distance Euclidienne.
Nous nous int√©ressons au calcul de la distance euclidienne entre des vecteurs repr√©sentant l‚Äôimage d‚Äôentr√©e et l‚Äôimage stock√©e dans la base de donn√©es afin de d√©terminer leurs similitudes.
Soient m ‚àà ùëÅ ‚àó , x= (ùë•1,...,ùë•ùëö) ‚àà R, et y= (ùë¶1,...,ùë¶ùëö) ‚àà R, la loi de calcul de la distance euclidienne comme ce suit : 

<img width="542" alt="face6" src="https://user-images.githubusercontent.com/113049750/197323404-5051b4a8-821c-413b-9df6-46c0ae8c071c.png">

Nous d√©terminons la distance entre leurs repr√©sentations vectorielles pour d√©cider si deux photos faciales sont identiques. Ces deux photos de visage sont class√©es comme repr√©sentant une m√™me personne si la distance est inf√©rieure √† une valeur seuil. Le seuil utilis√© ici est 0,6 qui est la valeur ayant permis d‚Äôobtenir les meilleurs r√©sultats (99,38 % de pr√©cision). 
Cette pr√©cision signifie que, lorsqu'il est pr√©sent√© avec une paire de visages, le mod√®le identifiera correctement si la paire appartient au m√™me personne ou provient de personnes diff√©rentes 99,38 % du temps.


## Description de la phase impl√©mentation


Dans le cadre de ce projet nous avons d√©velopp√© une application de microblogage XFact pour l‚Äô√©change d‚Äôinformations entre les employ√©s d‚Äôune soci√©t√© XFact fictive. L‚Äôapplication, inspir√©e du syst√®me de publications de Twitter, est privatis√©e. 

Cette application n‚Äôest en aucun cas une copie de Twitter et pr√©sente donc uniquement quelques fonctionnalit√©s nous permettant de mettre en ≈ìuvre l‚Äôint√©gration et la mise en exergue de notre syst√®me en mode gestion des acc√®s/ surveillance temps r√©el.  

Contrairement √† une application classique, aucun r√¥le ou profile d‚Äôacc√®s, outre que celui de l‚Äôadmin, n‚Äôa √©t√© d√©fini dans la partie administration de l‚Äôapplication. Toute l‚Äôarchitecture de gestion des acc√®s et de r√¥les (gestion des droits des utilisateurs) est bas√©e sur la reconnaissance faciale. 

### Les acteurs

- L‚Äôadministrateur ou le super-utilisateur. Il ou elle poss√®de tous les droits d‚Äôun utilisateur classique. En plus il dispose du droit d‚Äôacc√©der √† la partie administration (base de donn√©es) de l‚Äôapplication pour exercer diff√©rents droits vis-√†-vis des utilisateurs, publications et profiles. 
- Les utilisateurs qui disposent des droits de cr√©ation de publications, de modification et de suppression de publications dont ils sont les auteurs.

### La pr√©sentation

Page d'acceuil

<img width="732" alt="Capture d‚ÄôeÃÅcran 2022-10-22 aÃÄ 08 06 43" src="https://user-images.githubusercontent.com/113049750/197323396-a51a5538-f857-4f35-b471-e6c3950c3775.png">

Pages pr√©sentant les publications

Ces publications sont ordonn√©es de la plus r√©cente √† la plus ancienne, √† chaque rafraichissement de la page gr√¢ce √† la date de publication avec la vue PostListView 

<img width="732" alt="Capture d‚ÄôeÃÅcran 2022-10-22 aÃÄ 08 06 43" src="https://user-images.githubusercontent.com/113049750/197323397-6a8ca4f8-f4e8-4a68-adf0-d38336a9505e.png">

 Exemple de Profil
 
<img width="732" alt="Capture d‚ÄôeÃÅcran 2022-10-22 aÃÄ 08 06 43" src="https://user-images.githubusercontent.com/113049750/197323398-b9a6b324-f11d-4adb-ad19-c7a7538b4180.png">

### Fonctionnement

La fonction facedetect() permet d'√©valuer en temps r√©el un vecteur repr√©sentant l'identit√© de l'utilisateur courant et de le comparer avec un vecteur repr√©sentant l'identit√© du profile utilisateur pr√©sent au pr√©alable dans la base de donn√©es.

#### Succ√®s de la reconnaissance

En cas de succ√®s du processus d‚Äôauthentification √† double facteur, l‚Äôutilisateur est connect√© et le message suivant s‚Äôaffiche :

<img width="789" alt="Capture d‚ÄôeÃÅcran 2022-10-22 aÃÄ 08 04 24" src="https://user-images.githubusercontent.com/113049750/197323380-b2039d8b-4d61-43cc-af1f-e395c5fc83da.png">

Il peut donc acc√©der au contenu de l‚Äôapplication comme son profile, les publications des utilisateurs, ou encore la page de cr√©ation d‚Äôun nouveau post √† publier.


#### √âchec d'authentification et message d'alerte

<img width="852" alt="Capture d‚ÄôeÃÅcran 2022-10-22 aÃÄ 08 00 17" src="https://user-images.githubusercontent.com/113049750/197323376-116ede65-3ce7-46a5-b421-1c703dcae111.png">

Le syst√®me envoie instantan√©ment √† l‚Äôadministrateur du blog ainsi un mail d‚Äôalerte lui indiquant non seulement la phase du processus d‚Äôauthentification qui a √©chou√© mais aussi une image (capture) de l‚Äôindividu √† l‚Äôorigine de la tentative de violation.

<img width="732" alt="Capture d‚ÄôeÃÅcran 2022-10-22 aÃÄ 08 06 43" src="https://user-images.githubusercontent.com/113049750/197323384-650900cf-4967-4b1f-9bca-03828362ae13.png">


<img width="718" alt="vue  auth" src="https://user-images.githubusercontent.com/113049750/197323406-2635c862-2748-48b9-ac9e-31753f005357.png">

La fonction mailing pour l'envoi des messages d'alertes √† l'admin et au propri√©taire.

<img width="721" alt="mess al" src="https://user-images.githubusercontent.com/113049750/197323405-323a75a5-16df-463b-bb4e-1be2503feb03.png">

<img width="732" alt="Capture d‚ÄôeÃÅcran 2022-10-22 aÃÄ 08 06 14" src="https://user-images.githubusercontent.com/113049750/197323383-d934e8b3-3f3e-45cd-8ec3-157eb60fc312.png">

<img width="732" alt="Capture d‚ÄôeÃÅcran 2022-10-22 aÃÄ 08 06 06" src="https://user-images.githubusercontent.com/113049750/197323382-08fb7707-6489-4d77-8b71-09983059259c.png">  

Le rendu est le suivant :

<img width="852" alt="Capture d‚ÄôeÃÅcran 2022-10-22 aÃÄ 07 58 44" src="https://user-images.githubusercontent.com/113049750/197323374-c160cf5a-3567-4448-b92c-a6ea56f79717.png">

Cette phrase cl√¥ture la partie authentification de notre application.

L‚Äôapplication de notre syst√®me √† la gestion des acc√®s intervient aussi lors d‚Äôune tentative de modification ou de suppression du contenu d‚Äôun utilisateur (modification ou suppression d‚Äôune publication).


S'il d√©cide de consulter une publication de l‚Äôutilisateur Millie_1. Apr√®s clic, il est dirig√© vers la page suivante :

<img width="840" alt="Capture d‚ÄôeÃÅcran 2022-10-22 aÃÄ 08 02 32" src="https://user-images.githubusercontent.com/113049750/197323377-83644a3b-c56b-4b18-869f-1979d0721aef.png">

Il ne peut donc (puisque le syst√®me se base sur son profile pour la gestion des acc√®s) que consulter la publication.

<img width="848" alt="Capture d‚ÄôeÃÅcran 2022-10-22 aÃÄ 08 04 01" src="https://user-images.githubusercontent.com/113049750/197323379-2c828f5c-0923-44d8-98ff-5805899d7d15.png">

## Conclusion 

Le pr√©sent projet est satisfaisant dans l‚Äôensemble car il met bien en √©vidence, comme l‚Äô√©tait notre intention, l‚Äôid√©e de substituer la d√©finition des droits et la gestion des acc√®s classique avec une approche bas√©e sur l‚Äôutilisation de la vision par ordinateur (plus pr√©cis√©ment la reconnaissance faciale).
Il regroupe toutes les √©tapes d‚Äôimpl√©mentation du dit syst√®me ainsi qu‚Äôune pr√©sentation de son fonctionnement dans l‚Äôenvironnement de l‚Äôapplication pour les taches d‚Äôauthentification pour l‚Äôacc√®s √† l‚Äôapplication initialement, mais √©galement lors des tentatives d‚Äôalt√©rations d‚Äôinformations √† l‚Äôint√©rieur de la base de donn√©es (publications, utilisateurs et profiles) comme la modification ou la suppression du contenu utilisateur. 

Comme pr√©cis√© plus haut, aucune d√©finition de droits ou de privil√®ges en dehors de ceux qui d√©finissent primitivement l‚Äôadmin n‚Äôa √©t√© incluse lors de la conception et de l‚Äôimpl√©mentation. Toute la gestion des acc√®s et des droits est bas√©e uniquement sur le r√©sultat de l‚Äôauthentification comme impl√©ment√© dans les extraits de code python ins√©r√©s dans la pr√©sentation des vues. 

Toutes les autorisations d‚Äôacc√®s de l‚Äôapplication sont compl√®tement centr√©es sur la reconnaissance faciale de l‚Äôutilisateur connect√©, m√™me apr√®s succ√®s de la phase d‚Äôauthentification. 

